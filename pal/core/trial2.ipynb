{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below is going to be our interface.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 PAL Authors. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import io\n",
    "import signal\n",
    "from contextlib import redirect_stdout\n",
    "from typing import Any, Callable, List, Optional\n",
    "from collections import Counter\n",
    "\n",
    "# from .runtime import GenericRuntime\n",
    "# from .backend import call_gpt, call_chat_gpt\n",
    "from runtime import GenericRuntime\n",
    "from backend import call_gpt, call_chat_gpt\n",
    "\n",
    "# Removed since this won't work on windows anyway.\n",
    "# class timeout:\n",
    "#     def __init__(self, seconds=1, error_message='Timeout'):\n",
    "#         self.seconds = seconds\n",
    "#         self.error_message = error_message\n",
    "#     def timeout_handler(self, signum, frame):\n",
    "#         raise TimeoutError(self.error_message)\n",
    "#     def __enter__(self):\n",
    "#         signal.signal(signal.SIGALRM, self.timeout_handler)\n",
    "#         signal.alarm(self.seconds)\n",
    "#     def __exit__(self, type, value, traceback):\n",
    "#         signal.alarm(0)\n",
    "\n",
    "\n",
    "class TextInterface:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = 'code-davinci-002',\n",
    "        answer_prefix: str = 'The answer is:',\n",
    "        stop: str = '\\n\\n\\n',\n",
    "        extract_answer: Optional[Callable[[str], Any]] = None,\n",
    "    ):\n",
    "        self.history = []\n",
    "        self.answer_prefix = answer_prefix\n",
    "        self.extract_answer_fn = extract_answer\n",
    "        self.stop = stop\n",
    "        self.model = model\n",
    "        \n",
    "    def clear_history(self):\n",
    "        self.history = []\n",
    "    \n",
    "    def extract_answer(self, gen: str):\n",
    "        if self.extract_answer_fn:\n",
    "            return self.extract_answer_fn (gen)\n",
    "        last_line = gen.strip().split('\\n')[-1]\n",
    "        return last_line[len(self.answer_prefix):].strip()\n",
    "    \n",
    "    def run(self, prompt, temperature=0.0, top_p=1.0, majority_at=None, max_tokens=512):\n",
    "        gen = call_gpt(prompt, model=self.model, stop=self.stop, \n",
    "            temperature=temperature, top_p=top_p, max_tokens=max_tokens, majority_at=majority_at)\n",
    "        self.history.append(gen)\n",
    "        return self.extract_answer(gen)\n",
    "        \n",
    "\n",
    "class ProgramInterface:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = 'code-davinci-002',\n",
    "        runtime: Optional[Any] = None,\n",
    "        stop: str = '\\n\\n',\n",
    "        get_answer_symbol: Optional[str] = None,\n",
    "        get_answer_expr: Optional[str] = None,\n",
    "        get_answer_from_stdout: bool = False,\n",
    "        verbose: bool = False\n",
    "    ) -> None:\n",
    "\n",
    "        self.model = model\n",
    "        self.runtime = runtime if runtime else GenericRuntime()\n",
    "        self.history = []\n",
    "        self.stop = stop\n",
    "        self.answer_symbol = get_answer_symbol\n",
    "        self.answer_expr = get_answer_expr\n",
    "        self.get_answer_from_stdout = get_answer_from_stdout\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def clear_history(self):\n",
    "        self.history = []\n",
    "    \n",
    "    def process_generation_to_code(self, gens: str):\n",
    "        return [g.split('\\n') for g in gens]\n",
    "    \n",
    "    def generate(self, prompt: str, temperature: float =0.0, top_p: float =1.0, \n",
    "            max_tokens: int =512, majority_at: int =None, ):\n",
    "        gens = call_gpt(prompt, model=self.model, stop=self.stop, \n",
    "            temperature=temperature, top_p=top_p, max_tokens=max_tokens, majority_at=majority_at, )\n",
    "        if self.verbose:\n",
    "            print(gens)\n",
    "        code = self.process_generation_to_code(gens)\n",
    "        self.history.append(gens)\n",
    "        return code\n",
    "    \n",
    "    def execute(self, code: Optional[List[str]] = None):\n",
    "        # code = code if code else self.code\n",
    "        if self.get_answer_from_stdout:\n",
    "            program_io = io.StringIO()\n",
    "            with redirect_stdout(program_io):\n",
    "                self.runtime.exec_code('\\n'.join(code))\n",
    "            program_io.seek(0)\n",
    "            return program_io.readlines()[-1]\n",
    "        elif self.answer_symbol:\n",
    "            self.runtime.exec_code('\\n'.join(code))\n",
    "            return self.runtime._global_vars[self.answer_symbol]\n",
    "        elif self.answer_expr:\n",
    "            self.runtime.exec_code('\\n'.join(code))\n",
    "            return self.runtime.eval_code(self.answer_expr)\n",
    "        else:\n",
    "            self.runtime.exec_code('\\n'.join(code[:-1]))\n",
    "            return self.runtime.eval_code(code[-1])\n",
    "    \n",
    "    # def run(self, prompt: str, time_out: float =10, temperature: float =0.0, top_p: float =1.0, \n",
    "    #         max_tokens: int =512, majority_at: int =None):\n",
    "    #     code_snippets = self.generate(prompt, majority_at=majority_at, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
    "        \n",
    "    #     results = []\n",
    "    #     for code in code_snippets:\n",
    "    #         with timeout(time_out):\n",
    "    #             try:\n",
    "    #                 exec_result = self.execute(code)\n",
    "    #             except Exception as e:\n",
    "    #                 print(e)\n",
    "    #                 continue\n",
    "    #             results.append(exec_result)\n",
    "    #     counter = Counter(results)\n",
    "    #     return counter.most_common(1)[0][0]\n",
    "    \n",
    "    \n",
    "SYSTEM_MESSAGES = 'You are a helpful python programmer. Use comments to comment out non-executable lines and keep code separate from text.'\n",
    "class ProgramChatInterface(ProgramInterface):\n",
    "    def __init__(self, *args, system_message: str = SYSTEM_MESSAGES, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.system_message = system_message\n",
    "        \n",
    "    def generate(self, prompt: str, temperature: float = 0, top_p: float = 1, max_tokens: int = 512):\n",
    "        messages =[{'role': 'system', 'content': self.system_message}, {'role': 'user', 'content': prompt}]\n",
    "        gen = call_chat_gpt(messages, model=self.model, stop=self.stop, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
    "        if self.verbose:\n",
    "            print(gen)\n",
    "        self.history.append(gen)\n",
    "        return self.process_generation_to_code(gen)\n",
    "        \n",
    "    def process_generation_to_code(self, gens: str):\n",
    "        if '```python' in gens:\n",
    "            gens = gens.split('```python')[1].split('```')[0]\n",
    "        elif '```' in gens:\n",
    "            gens = gens.split('```')[1].split('```')[0]\n",
    "            \n",
    "        return gens.split('\\n')\n",
    "    \n",
    "    def run(self, prompt: str, time_out: float = 10, temperature: float = 0, top_p: float = 1, max_tokens: int = 512):\n",
    "        code = self.generate(prompt, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
    "        # with timeout(time_out):\n",
    "        results = []\n",
    "        code_errors = []\n",
    "        try:\n",
    "            exec_result = self.execute(code)\n",
    "            return exec_result\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATH_CHAT_BETA_SYSTEM_MESSAGE = 'You will write python program to solve math problems. You will only write code blocks.'\n",
    "MATH_CHAT_BETA_SYSTEM_MESSAGE = \"You will write a python function called 'solution' to solve math problems. Non code line should be prefixed with a '#'.\"\n",
    "question = 'Olivia has $50. She bought five bagels for $3 each. How much money does she have left?'\n",
    "\n",
    "MATH_CHAT_BETA_PROMPT = f'''\n",
    "Let's use python to solve math problems. Here are three examples how to do it,\n",
    "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
    "```\n",
    "def solution():\n",
    "    \"\"\"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\"\"\"\n",
    "    money_initial = 23\n",
    "    bagels = 5\n",
    "    bagel_cost = 3\n",
    "    money_spent = bagels * bagel_cost\n",
    "    money_left = money_initial - money_spent\n",
    "    result = money_left\n",
    "    return result\n",
    "```\n",
    "\n",
    "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\n",
    "```\n",
    "def solution():\n",
    "    \"\"\"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\"\"\"\n",
    "    golf_balls_initial = 58\n",
    "    golf_balls_lost_tuesday = 23\n",
    "    golf_balls_lost_wednesday = 2\n",
    "    golf_balls_left = golf_balls_initial - golf_balls_lost_tuesday - golf_balls_lost_wednesday\n",
    "    result = golf_balls_left\n",
    "    return result\n",
    "```\n",
    "\n",
    "Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\n",
    "```\n",
    "def solution():\n",
    "    \"\"\"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\"\"\n",
    "    computers_initial = 9\n",
    "    computers_per_day = 5\n",
    "    num_days = 4  # 4 days between monday and thursday\n",
    "    computers_added = computers_per_day * num_days\n",
    "    computers_total = computers_initial + computers_added\n",
    "    result = computers_total\n",
    "    return result\n",
    "```\n",
    "\n",
    "How about this question?\n",
    "Q: {question}\n",
    "'''.strip()\n",
    "# messages =[{'role': 'system', 'content': SYSTEM_MESSAGES}, {'role': 'user', 'content': MATH_CHAT_BETA_PROMPT}]\n",
    "# ans = openai.ChatCompletion.create(model='gpt-3.5-turbo', stop=None, temperature=0., top_p=1.0, max_tokens=128, n=1, messages=messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pci = ProgramChatInterface(model='gpt-3.5-turbo', system_message=MATH_CHAT_BETA_SYSTEM_MESSAGE)\n",
    "question = 'Shona has $150. She bought five bagels for $3 each. How much money does she have left?'\n",
    "prompt = MATH_CHAT_BETA_PROMPT.format(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use python to solve math problems. Here are three examples how to do it,\n",
      "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
      "```\n",
      "def solution():\n",
      "    \"\"\"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\"\"\"\n",
      "    money_initial = 23\n",
      "    bagels = 5\n",
      "    bagel_cost = 3\n",
      "    money_spent = bagels * bagel_cost\n",
      "    money_left = money_initial - money_spent\n",
      "    result = money_left\n",
      "    return result\n",
      "```\n",
      "\n",
      "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\n",
      "```\n",
      "def solution():\n",
      "    \"\"\"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\"\"\"\n",
      "    golf_balls_initial = 58\n",
      "    golf_balls_lost_tuesday = 23\n",
      "    golf_balls_lost_wednesday = 2\n",
      "    golf_balls_left = golf_balls_initial - golf_balls_lost_tuesday - golf_balls_lost_wednesday\n",
      "    result = golf_balls_left\n",
      "    return result\n",
      "```\n",
      "\n",
      "Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\n",
      "```\n",
      "def solution():\n",
      "    \"\"\"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\"\"\n",
      "    computers_initial = 9\n",
      "    computers_per_day = 5\n",
      "    num_days = 4  # 4 days between monday and thursday\n",
      "    computers_added = computers_per_day * num_days\n",
      "    computers_total = computers_initial + computers_added\n",
      "    result = computers_total\n",
      "    return result\n",
      "```\n",
      "\n",
      "How about this question?\n",
      "Q: Olivia has $50. She bought five bagels for $3 each. How much money does she have left?\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = pci.generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Here's the code block to solve the problem:\"]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
